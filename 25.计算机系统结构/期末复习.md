# 期末复习

## 性能评价

Million Instructions Per Second MIPS = 指令条数 / (执行时间 * 10^6)  $\propto\dfrac{Fz}{CPI}$

### Amdahl 定律

可改进部分比例 $Fe$  改进部分加速比 $Se$

整个系统加速比 $\dfrac{1}{1-F_e+F_e/S_e}$

## ISA

### 寻址技术

**编址方式**: 大端和小端

**寻址方式**: 寄存器寻址、立即数寻址、间接寻址和变址寻址...

**定位方式**: 直接定位-程序装载前, 静态定位-装载中, 动态定位-运行时

### 指令格式设计

固定长度编码

Huffman 编码

- 操作码的最短平均长度
  $$
  H=-\sum_{i=1}^n p_i\log_2{p_i}
  $$
  信息冗余 $R = 1 - H / \text{指令平均长度}$


扩展编码

### RISC & VLIW

**RISC** 

- 只有load 和 stroe 指令访存
- 三地址指令, 大部分指令可以单周期执行完成

VLIW 超长指令字: 一种显示的**指令级并行指令系统**.

## Memory

核心问题与解决方案：CPU-Memory Bottleneck —— 层次结构

### Cache

四个基本问题：

1. 物理地址到缓存块的映射：直接相联，全相联，组相联
2. 确定缓存块对应的物理地址
3. 缓存替换策略：LRU, Random...
4. 写命中 / 写缺失行为：写回/写直达 (搭配 write buffer)，写分配/写不分配

缓存缺失种类：必然缺失、容量缺失、冲突缺失...

假设有 $m$ 比例指令访存，则总访存次数为 $(1 + m)\times IC $ 

平均访存时间：
$$
AMAT = t_{hit}+\alpha_{miss} t_{miss}
$$

> 优化技术了解即可

**降低缺失率**

1. 适中的 block size：过大增加冲突损失，过小增加必然损失
2. 更大的 Cache：同时增加成本和命中时间
3. 更高的相连度
4. Way Prediction & Pseudo-Associative Cache

5. 编译优化
6. 指令/数据预取

**降低缺失损失**

1. 多级cache，Write buffer
   - Inclusive or Exclusive
   - 一级指令缓存和数据缓存分开，能够并行访问
2. Critical Word First and Early Restart: 目标字准备好就唤醒 CPU
3. Giving Priority to Read Misses over Writes: 从 write buffer 中读数据
4. Merging Write Buffer
5. Victim Caches

**降低命中时间**

1. 更小更简单的Cache

2. 防止地址转换——**为什么 Cache 不用虚地址索引**？

   每次进程切换都要刷新 cache => 可以给cache line增加一个进程域

   虚地址空间存在**别名问题 aliases**，可能有重复映射的数据。

### 并行存储器的无冲突访问

**并行存储器**高位交叉提高存储容量，低位交叉提高访存速度。

**无冲突访问**：

- 一维数组：存储体个数取质数，且不小于向量长度。
- 二维数组 略有点复杂，不记忆了。

## CPU

### Pipeline

表示方式：时空图，连接图

静态流水线：当流水线要切换到另一种功能时，必须等前面的任务都流出流水线之后，才能改变连接

线性流水线：每个流水段恰好流过一次

非线性流水线：某些流水段之间有前馈和反馈回路

#### 性能分析

设有 $n$ 个任务，流水线有 $k$ 段，时钟周期为 $\Delta t$

- 吞吐率是任务数量与用时之比， $TP = \dfrac{n}{T_k}=\dfrac{n}{(k+n-1)\Delta t}\rightarrow 1/\Delta t$

- 加速比是非流水线用时与流水线之比，$S=\dfrac{kn}{k+n-1}\rightarrow k$
- 效率为 n 个任务所占时空区占所有时空区的比例，$E = S/k=TP\cdot \Delta t=\dfrac{n}{k+n-1}\rightarrow 1$

若流水线各段执行时间不相等 $TP=\dfrac{n}{T_k}=\dfrac{n}{(\sum\Delta t_i)+(n-1)\max{(\Delta t_i)}}$

- 解决办法：瓶颈流水段再细分，重复设置资源

#### 非线性流水线调度

用预约表表示，预约表和流水线连接图不能一一对应。

##### 无冲突调度

启动距离：连续输入两个任务之间的时间间隔

根据预约表写出禁止启动集合 $F$：预约表中**每一行任意两个“×” 之间距离的集合**，

根据 F 构造初始冲突向量 $C_0$。

根据 $C_0$ 构造状态图：

- 把冲突向量送入一个m位逻辑右移移位器；如果移位器移出0，用移位器中的值与初始冲突向量作按位或，得到新的冲突向量；如此重复m次。 

  对于中间形成的每一个新的冲突向量，也按照这一方法进行处理。

- 简单循环：状态图中冲突向量经过少于一次的启动循环。

##### 预留算法

1. 确定最小平均启动距离，即预约表任一行中“×”的最多个数
2. 确定最小启动循环。一般以恒定循环作为最小启动循环
3. 通过插入非计算延迟段--修改预约表实现最小启动循环，任一行中与第1个“×”的距离为最小启动循环倍数的周期都要预留出来。

对于启动循环 C，记其循环周期为 $p$，可推导出各个启动时刻之间所有可能的时间间隔 $G_c \pmod{p}$，称为时间间隔集合。对于禁止启动集合为 $F$ 的流水线，$C$ 无冲突等价于 $G_c\pmod p\cap F\pmod p=\empty$.

> eg. 对于 C = {1， 3}， p = 4，Gc (mod 4) = {0, 1, 3} 可知 F(mod 4) = {2}

#### 高级流水线

![image-20210613144903502](.\readme_pic\image-20210613144903502.png)

**超标量**

设置多条指令流水线，同时发射多条指令。

先行指令窗口：能够从指令Cache中预取多条指令，对窗口内的指令进行数据相关性分析和功能部件冲突检测。

乱序发射乱序完成， 必须使用先行指令窗口。

> 普通标量处理机，希望相同操作连续出现，以使流水不断流；而超标量处理机希望相同操作的指令能够相对均匀地分布在程序中，减少资源冲突。

**超流水线**

分时使用同一条指令流水线的不同部分，或指令流水线的功能段数为8段或超过8段的流水线。

**超标量超流水线**

### 静态调度

优化技术集中于编译层面。

指令级并行：基本块内的并行

- 通过编译优化减少数据依赖、名称依赖、控制依赖带来的 stall

延迟转移技术：在分支指令后增加延迟槽，提高利用率

重排指令，重命名寄存器，循环展开...

### 动态调度 Tomasulo

> 算法与体系结构高度相关，详见slide

三阶段：Issue，Execute，Write result

顺序 Issue，乱序 Execute 和 Write result.

-  CDB 成为性能瓶颈
- Dynamic scheduling，Register renaming---消除了WAW，WAR 相关

#### Tomasulo with ROB

ROB Re-order buffer 更改后的算法能够支持精确异常和分支预测。

> Technique for both precise interrupts/exceptions and speculation: **in-order commit** 

为寄存器组增加了 ROB，记录已完成未 commit 指令。

- commit 操作实际上是维护 ROB 表中的 head/ tail 指针

### Register Renaming

Decode does register renaming and adds instructions to the issue-stage instruction reorder buffer (ROB).

- RAW 是 True dependence，而 WAW、WAR 可以通过寄存器重命名消除。

Rigster map 由硬件维护的架构寄存器到物理寄存器映射。

指令 commit 时重用物理寄存器。

### branch prediction

> the potential stalling due to branches is greater

静态、动态：1 bit，2 bit

Branch Target Buffer

```python
if pc in BTB:
    if jump:
        执行 BTB[pc], 流水线不断流
    else:
        清除已取指令 stall
else:
    if jump:
        stall
    else:
        执行 pc + 4
```

- 在经典的5段流水线中，ID段末尾才能获得分支目标地址。而采用BTB可以提前在IF段就知道这些信息，从而降低 CPI。

## 互连网络

由**开关元件**按**一定拓扑结构和控制方式**构成的网络，以实现计算机系统内部多个处理机或多个功能部件间的相互连接。

### 互联函数

恒等函数

方体函数 $cube_k(X_{n-1}X_{n-2}\cdots X_k\cdots X_0)=X_{n-1}X_{n-2}\cdots \overline X_k\cdots X_0$.

洗牌函数

- 循环左移 $Sh(X_{n}X_{n-1}\cdots X_1)=X_{n-1}\cdots X_1X_n$ 
- 变种：均匀洗牌—循环左移+cube0、子洗牌—低 k 位循环左移、超洗牌—高 k 位循环左移、逆洗牌 (循环右移)

蝶式：交换 $X_n$ 和 $X_1$

PM2I 

$PM2_{+i}(j)=j+2^i\pmod{N}, PM2_{-i}(j)=j-2^i\pmod{N}$

其中 $0\le j \le N-1,0\le i \le log_2N-1$

### 静态网络和动态网络

分类标准：网络拓扑在程序执s行中是否改变。

各种典型的网络结构：

- 静态：k元n-立方体网络 (节点数 $N = k^n$)

  lllica 网，由 $PM2_{\pm 0}$, $PM2_{\pm2}$ 组成，有 $r \times r$ 个节点，直径为 $r-1$，节点度为 4.

- 动态：交叉开关，

  $\Omega$ 网 设有 $p$ 个处理器，交换器有 $log_2p$ 层，每层 $p/2$ 个

###  通信

节点距离 $D$，消息长度 $L$，通信带宽 $B$，$T_p$ 是消息在它所经过的路径上每个中间结点的平均时延

网络时延 $T_n=DT_p+L/B$

**寻径算法**

存储转发 $T_n=(D+1)L/B$

虚拟直通 $T_n=(L_hD+L)/B$	$L_h$ 报文头到寻路信息的长度

线路开关 $T_n=(L_cD+L)/B$	$L_c$ 控制报文长度

Wormhole $T_n=(L_fD+L)/B$	$L_f$ 分片长度

## 数据并行

> TPU 和 GPU 选学

### Vector Architeture

具有向量数据表示 (**向量寄存器**) 和相应的**向量指令集**的流水线处理器，称为**向量处理机**。

- 更少的指令和操作，更少的流水线冲突

向量平衡点：向量运算速度 / (向量运算速度 + 标量运算速度)，程序中向量指令的比例达到向量平衡点时，向量设备和标量设备利用率相同。

**数据表示**

等间距向量表示法：起始地址，长度，元素间距

带位移量的向量表示法：基地址，长度，偏移量 (起始地址 = 基地址 + 偏移量)

稀疏向量表示法：压缩向量 + 压缩位 Bitmap

**处理方式**

横向处理：不适合并行

纵向处理

纵横（分组处理）：分成多组，组内纵向处理，依次处理各组。

**处理机结构**

存储器-存储器

寄存器-寄存器

**性能优化**

1. 多个并行工作的功能部件，多处理机系统； 

2. **向量链接 vector chaining**：把功能部件链接起来，使向量数据能在流水线上直接前传

   条件：**源向量、功能部件都不相同，有先写后读**

   链接时，把向量数据元素送往向量功能部件以及把结果存入向量寄存器都需要一拍时间，从存储器中把数据送入访存功能部件也需要一拍时间。

   当一条向量指令的两个源操作数分别是两条先行指令的结果寄存器时，要求先行的两条指令产生运算结果 的时间必须相等。

3. 循环开采：把长向量分成长度固定的段，每一次循环只处理一个向量段。

> 性能评价 不看了

### Array Processor

阵列处理机：控制部件 CU 通过互联网络控制多个处理单元 PU.

依赖于互连网络和并行算法。

基本结构，分布存储和共享存储：后者更快，但可扩展性不高

- 注意与 Vector Architecture 的区别。

  
